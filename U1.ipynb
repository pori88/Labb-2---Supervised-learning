{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1ab2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bc182bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccce1956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "      <td>1599.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.32</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15.87</td>\n",
       "      <td>46.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.42</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.74</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10.46</td>\n",
       "      <td>32.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.60</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.33</td>\n",
       "      <td>8.40</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.90</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>14.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>21.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.10</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.90</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.61</td>\n",
       "      <td>72.00</td>\n",
       "      <td>289.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>14.90</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count        1599.00           1599.00      1599.00         1599.00   \n",
       "mean            8.32              0.53         0.27            2.54   \n",
       "std             1.74              0.18         0.19            1.41   \n",
       "min             4.60              0.12         0.00            0.90   \n",
       "25%             7.10              0.39         0.09            1.90   \n",
       "50%             7.90              0.52         0.26            2.20   \n",
       "75%             9.20              0.64         0.42            2.60   \n",
       "max            15.90              1.58         1.00           15.50   \n",
       "\n",
       "       chlorides  free sulfur dioxide  total sulfur dioxide  density       pH  \\\n",
       "count    1599.00              1599.00               1599.00  1599.00  1599.00   \n",
       "mean        0.09                15.87                 46.47     1.00     3.31   \n",
       "std         0.05                10.46                 32.90     0.00     0.15   \n",
       "min         0.01                 1.00                  6.00     0.99     2.74   \n",
       "25%         0.07                 7.00                 22.00     1.00     3.21   \n",
       "50%         0.08                14.00                 38.00     1.00     3.31   \n",
       "75%         0.09                21.00                 62.00     1.00     3.40   \n",
       "max         0.61                72.00                289.00     1.00     4.01   \n",
       "\n",
       "       sulphates  alcohol  quality  \n",
       "count    1599.00  1599.00  1599.00  \n",
       "mean        0.66    10.42     5.64  \n",
       "std         0.17     1.07     0.81  \n",
       "min         0.33     8.40     3.00  \n",
       "25%         0.55     9.50     5.00  \n",
       "50%         0.62    10.20     6.00  \n",
       "75%         0.73    11.10     6.00  \n",
       "max         2.00    14.90     8.00  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- 1. Data understanding\n",
    "\n",
    "# Denna cell är för att ge oss ännu mer djupgående info så att vi kan undersöka datan och få en helhetsbild på det som ska undersökas utifrån statistikt tänk.\n",
    "# Denna cell är även för att undersöka datan. Det man vill hitta är features och target. \n",
    "# Utifrån detta kan man se att vi har 11 features och 1 target vilket är ''quality''.\n",
    "\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3f08d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Denna skapas för att visa klassfördelningar. Utifrån detta kan vi se en tydlig obalans pga de första två klasserna eftersom dessa har hundratals\n",
    "#observationer medan andra bara har fåtal. Detta påverkar hur bra klassificieringsmodellen kan lära sig minoritetsklasserna.\n",
    "\n",
    "#Varför är detta viktigt? Jo, pga accuracy blir missvisande (modellen kan få 50% accuracy genom klass 5 och 6) och k-NN påverkas mycket genom att minoritetspunkterna\n",
    "#får vädigt få 'grannar' vilket leder till stor risk att bli felklassificerade.\n",
    "df[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cce339c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- 2. Data preparation\n",
    "\n",
    "# I denna cell börjar vi gå till delen då vi ska börja förbereda datan för arbete. \n",
    "# Det vi är ute efter här: X= features och y=target. Vi ska skapa tränings- och testdata. normaliserad vs icke-normaliserad data.\n",
    "# Vi behöver dela upp datan i X och y för att algoritmen ska lära sig sambandet.\n",
    "\n",
    "X = df.drop (\"quality\", axis=1)\n",
    "\n",
    "y = df[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87c910bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 11), (1599,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vi måste även kontrollera att data + label är korrekt separerade. Detta gör vi med hjälp av denna cell.\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4af3c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanken är att vi ska tre olika splittar; 90%train-10%test | 66%train - 33%test | 50%train - 50%test. \n",
    "# Detta krävs för att jämföra hur datamängden påverkar kNN, visa att mindre testdata get instabilare accuracy och att visa att större träningsmängd\n",
    "# ofta ger bättre resultat. \n",
    "# Det man har gjort här är att dela upp datan i träningsdelar och testdelar. Vi förbereder alltså datan för modellerna.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_90, X_test_10, y_train_90, y_test_10 = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42\n",
    ")\n",
    "\n",
    "X_train_66, X_test_33, y_train_66, y_test_33 = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(\n",
    "    X, y, test_size=0.50, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8ca1edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 160)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Denna cell används endast som kontroll för att se hur många rader som hamnade i train och test.\n",
    "len(X_train_90), len(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f29d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Här importerar vi och skapar normaliseringsverktyget för att utföra normaliseringen i kommande steg.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8ede5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37168142, 0.08219178, 0.35      , 0.05479452, 0.07178631,\n",
       "        0.16901408, 0.07420495, 0.28414097, 0.31496063, 0.15568862,\n",
       "        0.44615385],\n",
       "       [0.23893805, 0.1369863 , 0.23      , 0.09589041, 0.09015025,\n",
       "        0.47887324, 0.22614841, 0.42657856, 0.54330709, 0.17365269,\n",
       "        0.26153846],\n",
       "       [0.46902655, 0.28082192, 0.57      , 0.10273973, 0.13522538,\n",
       "        0.4084507 , 0.16254417, 0.51615272, 0.35433071, 0.25748503,\n",
       "        0.49230769],\n",
       "       [0.26548673, 0.3869863 , 0.23      , 0.09589041, 0.16527546,\n",
       "        0.26760563, 0.27561837, 0.46475771, 0.37007874, 0.16766467,\n",
       "        0.13846154],\n",
       "       [0.38938053, 0.32876712, 0.29      , 0.07534247, 0.0951586 ,\n",
       "        0.43661972, 0.23674912, 0.47503671, 0.47244094, 0.14371257,\n",
       "        0.24615385]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Det viktiga är att vi normaliserar endast features och inte target. En viktig detalj är att vi får inte normalisera hela datasetet för split för att detta\n",
    "# skulle läcka information från testdatan till träningsdatan och detta får absolut inte hända.\n",
    "\n",
    "# Vi normaliserar till intervallet [0,1] eftersom kNN och SVM använder avståndsberäkningar. \n",
    "# Om features har olika skalor kan avståndet snedvridas. Decision trees påverkas däremot knappt av normalisering vilket är bra.\n",
    "\n",
    "# Denna normaliserar data för 90/10\n",
    "scaler_90 = MinMaxScaler()\n",
    "X_train_90_norm = scaler_90.fit_transform(X_train_90)\n",
    "X_test_10_norm = scaler_90.transform(X_test_10)\n",
    "\n",
    "# Denna normaliserar data för 66/33\n",
    "scaler_66 = MinMaxScaler()\n",
    "X_train_66_norm = scaler_66.fit_transform(X_train_66)\n",
    "X_test_33_norm = scaler_66.transform(X_test_33)\n",
    "\n",
    "# Denna normaliserar data för  50/50\n",
    "scaler_50 = MinMaxScaler()\n",
    "X_train_50_norm = scaler_50.fit_transform(X_train_50)\n",
    "X_test_50_norm = scaler_50.transform(X_test_50)\n",
    "\n",
    "# Denna kodsnutt testar normaliseringen och visar den nedan. dd\n",
    "X_train_90_norm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd1db2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Här importerar vi kNN + metrics för att utföra kommande delar.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2c8db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denna funktion är skapad just för att slippa skriva samma kod 18 gånger. Det blir mer strukturerat. \n",
    "# Sedan kan man loopa genom alla körningarna.\n",
    "def run_knn(X_train, X_test, y_train, y_test, k):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return cm, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4c5d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Det som ska ske här är att vi skapar 3 tester med olika k-värden som vi väljer. 2 dataset varianter alltså ickenormaliserad och normaliserad.\n",
    "# Vi ska även ha med 3 train/test splittar. Totalt blir det alltså 18 körningar. Just därför la vi till funktionen ovan så att det ska bli smidigt att göra detta.\n",
    "# Med varje körning ska vi även visa confusion matrix och accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28582ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  1,  0,  0,  0],\n",
       "        [ 0,  1,  1,  1,  0,  0],\n",
       "        [ 0,  2, 43, 21,  2,  0],\n",
       "        [ 0,  4, 29, 28,  5,  0],\n",
       "        [ 0,  0,  5,  8,  3,  2],\n",
       "        [ 0,  0,  1,  1,  2,  0]], dtype=int64),\n",
       " 0.46875)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vi börjar med 90/10 splitten med k = 3. Icke-normaliserad data.\n",
    "cm_90_k3, acc_90_k3 = run_knn(X_train_90, X_test_10, y_train_90, y_test_10, k=3)\n",
    "\n",
    "cm_90_k3, acc_90_k3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "461f47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I denna del så ska vi loopa igenom alla 18 körningarna för att ha en smidig struktur. \n",
    "# Vi kommer att definiera alla tre k-värden, skapa en lista över alla train/test-splittar, skapa en lista över normaliseringstatus. Sedan kommer loopen att köras automatiskt.\n",
    "\n",
    "results = []\n",
    "\n",
    "k_values = [5, 17, 21]\n",
    "\n",
    "splits = [\n",
    "    (\"90/10 original\", X_train_90, X_test_10, y_train_90, y_test_10),\n",
    "    (\"90/10 norm\", X_train_90_norm, X_test_10_norm, y_train_90, y_test_10),\n",
    "\n",
    "    (\"66/33 original\", X_train_66, X_test_33, y_train_66, y_test_33),\n",
    "    (\"66/33 norm\", X_train_66_norm, X_test_33_norm, y_train_66, y_test_33),\n",
    "\n",
    "    (\"50/50 original\", X_train_50, X_test_50, y_train_50, y_test_50),\n",
    "    (\"50/50 norm\", X_train_50_norm, X_test_50_norm, y_train_50, y_test_50),\n",
    "]\n",
    "\n",
    "for name, Xtr, Xte, ytr, yte in splits:\n",
    "    for k in k_values:\n",
    "        cm, acc = run_knn(Xtr, Xte, ytr, yte, k)\n",
    "        results.append((name, k, acc, cm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "240f5077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 90/10 original | k = 5\n",
      "Accuracy: 0.475\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  2  1  0  0]\n",
      " [ 0  1 41 23  3  0]\n",
      " [ 0  1 31 32  2  0]\n",
      " [ 0  0  5  9  3  1]\n",
      " [ 0  0  1  2  1  0]]\n",
      "--------------------------------------------------\n",
      "Split: 90/10 original | k = 17\n",
      "Accuracy: 0.4813\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  2  1  0  0]\n",
      " [ 0  0 42 24  2  0]\n",
      " [ 0  0 31 34  1  0]\n",
      " [ 0  0  6 11  1  0]\n",
      " [ 0  0  1  2  1  0]]\n",
      "--------------------------------------------------\n",
      "Split: 90/10 original | k = 21\n",
      "Accuracy: 0.5375\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  2  1  0  0]\n",
      " [ 0  0 46 20  2  0]\n",
      " [ 0  0 26 39  1  0]\n",
      " [ 0  0  6 11  1  0]\n",
      " [ 0  0  1  3  0  0]]\n",
      "--------------------------------------------------\n",
      "Split: 90/10 norm | k = 5\n",
      "Accuracy: 0.5437\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  1  0  0]\n",
      " [ 0  0  1  2  0  0]\n",
      " [ 0  1 51 16  0  0]\n",
      " [ 0  1 31 28  6  0]\n",
      " [ 0  0  1  9  8  0]\n",
      " [ 0  0  0  2  2  0]]\n",
      "--------------------------------------------------\n",
      "Split: 90/10 norm | k = 17\n",
      "Accuracy: 0.5813\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  1  2  0  0]\n",
      " [ 0  0 50 18  0  0]\n",
      " [ 0  0 24 39  3  0]\n",
      " [ 0  0  2 12  4  0]\n",
      " [ 0  0  0  2  2  0]]\n",
      "--------------------------------------------------\n",
      "Split: 90/10 norm | k = 21\n",
      "Accuracy: 0.5563\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  2  1  0  0]\n",
      " [ 0  0 48 20  0  0]\n",
      " [ 0  0 25 38  3  0]\n",
      " [ 0  0  0 15  3  0]\n",
      " [ 0  0  0  3  1  0]]\n",
      "--------------------------------------------------\n",
      "Split: 66/33 original | k = 5\n",
      "Accuracy: 0.4792\n",
      "Confusion Matrix:\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   1   8   9   1   0]\n",
      " [  0   1 132  79   5   0]\n",
      " [  0   2  96 107   8   0]\n",
      " [  0   0  20  37  13   0]\n",
      " [  0   0   1   6   0   0]]\n",
      "--------------------------------------------------\n",
      "Split: 66/33 original | k = 17\n",
      "Accuracy: 0.4924\n",
      "Confusion Matrix:\n",
      "[[  0   0   1   1   0   0]\n",
      " [  0   0   9  10   0   0]\n",
      " [  0   0 146  69   2   0]\n",
      " [  0   0  97 109   7   0]\n",
      " [  0   0  24  41   5   0]\n",
      " [  0   0   1   6   0   0]]\n",
      "--------------------------------------------------\n",
      "Split: 66/33 original | k = 21\n",
      "Accuracy: 0.4886\n",
      "Confusion Matrix:\n",
      "[[  0   0   1   0   1   0]\n",
      " [  0   0   7  12   0   0]\n",
      " [  0   0 141  72   4   0]\n",
      " [  0   0  96 111   6   0]\n",
      " [  0   0  21  43   6   0]\n",
      " [  0   0   1   6   0   0]]\n",
      "--------------------------------------------------\n",
      "Split: 66/33 norm | k = 5\n",
      "Accuracy: 0.5492\n",
      "Confusion Matrix:\n",
      "[[  0   0   1   1   0   0]\n",
      " [  0   1   6  11   1   0]\n",
      " [  0   2 149  63   3   0]\n",
      " [  0   1  75 117  20   0]\n",
      " [  0   0   8  39  23   0]\n",
      " [  0   0   1   1   5   0]]\n",
      "--------------------------------------------------\n",
      "Split: 66/33 norm | k = 17\n",
      "Accuracy: 0.5398\n",
      "Confusion Matrix:\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0   8  11   0   0]\n",
      " [  0   0 151  63   3   0]\n",
      " [  0   0  83 115  15   0]\n",
      " [  0   0   5  46  19   0]\n",
      " [  0   0   0   4   3   0]]\n",
      "--------------------------------------------------\n",
      "Split: 66/33 norm | k = 21\n",
      "Accuracy: 0.5511\n",
      "Confusion Matrix:\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  10   9   0   0]\n",
      " [  0   0 152  63   2   0]\n",
      " [  0   0  73 124  16   0]\n",
      " [  0   0   5  50  15   0]\n",
      " [  0   0   0   4   3   0]]\n",
      "--------------------------------------------------\n",
      "Split: 50/50 original | k = 5\n",
      "Accuracy: 0.4838\n",
      "Confusion Matrix:\n",
      "[[  0   0   2   1   0   0]\n",
      " [  0   1  10  16   1   0]\n",
      " [  0   3 207 141   4   0]\n",
      " [  0   1 122 163  16   0]\n",
      " [  0   1  28  56  16   0]\n",
      " [  0   0   3   6   2   0]]\n",
      "--------------------------------------------------\n",
      "Split: 50/50 original | k = 17\n",
      "Accuracy: 0.4975\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   3   0   0]\n",
      " [  0   0  13  14   1   0]\n",
      " [  0   0 218 132   5   0]\n",
      " [  0   0 126 171   5   0]\n",
      " [  0   0  27  65   9   0]\n",
      " [  0   0   3   8   0   0]]\n",
      "--------------------------------------------------\n",
      "Split: 50/50 original | k = 21\n",
      "Accuracy: 0.5125\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   3   0   0]\n",
      " [  0   0  12  16   0   0]\n",
      " [  0   0 225 128   2   0]\n",
      " [  0   0 122 176   4   0]\n",
      " [  0   0  23  69   9   0]\n",
      " [  0   0   2   9   0   0]]\n",
      "--------------------------------------------------\n",
      "Split: 50/50 norm | k = 5\n",
      "Accuracy: 0.5563\n",
      "Confusion Matrix:\n",
      "[[  1   0   1   1   0   0]\n",
      " [  0   1  13  14   0   0]\n",
      " [  0   2 227 121   5   0]\n",
      " [  0   0  90 182  30   0]\n",
      " [  0   0  14  53  34   0]\n",
      " [  0   0   4   2   5   0]]\n",
      "--------------------------------------------------\n",
      "Split: 50/50 norm | k = 17\n",
      "Accuracy: 0.5387\n",
      "Confusion Matrix:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  13  14   1   0]\n",
      " [  0   0 233 120   2   0]\n",
      " [  0   0 109 168  25   0]\n",
      " [  0   0   7  64  30   0]\n",
      " [  0   0   0   7   4   0]]\n",
      "--------------------------------------------------\n",
      "Split: 50/50 norm | k = 21\n",
      "Accuracy: 0.5425\n",
      "Confusion Matrix:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14  14   0   0]\n",
      " [  0   0 231 122   2   0]\n",
      " [  0   0 105 175  22   0]\n",
      " [  0   0   9  64  28   0]\n",
      " [  0   0   0   6   5   0]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Denna cell loopar alltså igenom resultatet och skriver ut en lista som presenterar körningen.\n",
    "for r in results:\n",
    "    print(\"Split:\", r[0], \"| k =\", r[1])\n",
    "    print(\"Accuracy:\", round(r[2], 4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(r[3])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "605f5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BÄSTA RESULTATET\n",
      "Split: 90/10 norm | k = 17\n",
      "Accuracy: 0.5813\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  1  2  0  0]\n",
      " [ 0  0 50 18  0  0]\n",
      " [ 0  0 24 39  3  0]\n",
      " [ 0  0  2 12  4  0]\n",
      " [ 0  0  0  2  2  0]]\n",
      "--------------------------------------------------\n",
      "BÄSTA RESULTATET\n",
      "Split: 90/10 norm | k = 21\n",
      "Accuracy: 0.5563\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  2  1  0  0]\n",
      " [ 0  0 48 20  0  0]\n",
      " [ 0  0 25 38  3  0]\n",
      " [ 0  0  0 15  3  0]\n",
      " [ 0  0  0  3  1  0]]\n",
      "--------------------------------------------------\n",
      "BÄSTA RESULTATET\n",
      "Split: 50/50 norm | k = 5\n",
      "Accuracy: 0.5563\n",
      "Confusion Matrix:\n",
      "[[  1   0   1   1   0   0]\n",
      " [  0   1  13  14   0   0]\n",
      " [  0   2 227 121   5   0]\n",
      " [  0   0  90 182  30   0]\n",
      " [  0   0  14  53  34   0]\n",
      " [  0   0   4   2   5   0]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Efter att ha gjort alla 18 körningar sorterade vi resultatet efter accuracy. \n",
    "# Nu är målet att hitta de tre bästa körningarna (top 3 accuracy)\n",
    "# Detta gör vi genom att: 1. Sortera resultaten, 2. plocka ut top 3, 3. Visa confusion matrix och accuracy för dem och 4. Förklara kort varför dessa presterade bäst\n",
    "\n",
    "# Sortera resultaten efter accuracy (högst först)\n",
    "sorted_results = sorted(results, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Plocka ut de tre bästa\n",
    "top3 = sorted_results[:3]\n",
    "\n",
    "# Denna del skriver ut dem snyggt\n",
    "for r in top3:\n",
    "    print(\"BÄSTA RESULTATET\")\n",
    "    print(\"Split:\", r[0], \"| k =\", r[1])\n",
    "    print(\"Accuracy:\", round(r[2], 4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(r[3])\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "# Det vi kan se här är att nästan alla toppresultat ligger på normaliserad data eftersom kNN beräknar avstånd. Dessutom påverkar val av k och mängden träningsdata resultatet mycket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff48fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hur kan man läsa av detta?\n",
    "\n",
    "# I vår bästa körning (90/10), normaliserad data, k 17, får vi en accuracy på ca 0.58.\n",
    "# Om vi tittar på confusion matrixen ser vi att modellen framför allt lyckas med de vanligaste klasserna 5 och 6. \n",
    "# Till exempel klassificeras 50 av 68 femmor korrekt och 39 av 66 sexor korrekt.\n",
    "# De ovanliga klasserna, som 3, 4 och 8, klassificeras däremot nästan alltid fel - ofta som 5 och 6.\n",
    "# Detta hör självklart ihop med det som nämndes i början av labben alltså det är obalanserat vilket leder till att kNN tittar på närmaste grannar. \n",
    "# Eftersom det är 5 och 6 som dominerar, så kommer de andra siffrorna att blanda ihop sig med dem.\n",
    "# När det bara finns några enstaka exempel av en klass kommer deras grannar ofta att tillhöra de deominerande klasserna.\n",
    "# Slutsatsen är att confusion matrixen visar alltså att modellen fungerar hyfsat för de stora klasserna, men har dålig prestanda på minoritetsklasserna, trots att\n",
    "# den här inställningen ger högst total accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982eb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
